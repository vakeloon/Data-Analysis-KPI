{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-04T14:29:53.053808Z",
     "start_time": "2025-01-04T14:29:41.835243Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:30:48.800438Z",
     "start_time": "2025-01-04T14:30:48.787750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration\n",
    "batch_size = 64  \n",
    "epochs = 100 \n",
    "latent_dim = 256  \n",
    "num_samples = 10000\n",
    "data_path = \"ukr.txt\""
   ],
   "id": "ab93b3b8256b80d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:33:31.727585Z",
     "start_time": "2025-01-04T14:33:31.458851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vectorize the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ],
   "id": "e8c54dc2e1441216",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 72\n",
      "Number of unique output tokens: 96\n",
      "Max sequence length for inputs: 15\n",
      "Max sequence length for outputs: 54\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:34:38.139264Z",
     "start_time": "2025-01-04T14:34:37.808230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ],
   "id": "23d83a5974117866",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:35:45.417914Z",
     "start_time": "2025-01-04T14:35:44.293675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Building model\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ],
   "id": "660b19a46451f298",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T15:18:50.530260Z",
     "start_time": "2025-01-04T14:36:07.238213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save(\"s2s_model.keras\")"
   ],
   "id": "cf07cbb452cb07db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 206ms/step - accuracy: 0.7136 - loss: 1.5448 - val_accuracy: 0.7307 - val_loss: 1.0331\n",
      "Epoch 2/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m43s\u001B[0m 344ms/step - accuracy: 0.7573 - loss: 0.9453 - val_accuracy: 0.7514 - val_loss: 0.9238\n",
      "Epoch 3/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 207ms/step - accuracy: 0.7746 - loss: 0.8571 - val_accuracy: 0.7683 - val_loss: 0.8523\n",
      "Epoch 4/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 194ms/step - accuracy: 0.7898 - loss: 0.7797 - val_accuracy: 0.7879 - val_loss: 0.7717\n",
      "Epoch 5/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 192ms/step - accuracy: 0.8075 - loss: 0.6889 - val_accuracy: 0.7900 - val_loss: 0.7392\n",
      "Epoch 6/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m35s\u001B[0m 280ms/step - accuracy: 0.8134 - loss: 0.6551 - val_accuracy: 0.8030 - val_loss: 0.6831\n",
      "Epoch 7/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 189ms/step - accuracy: 0.8208 - loss: 0.6251 - val_accuracy: 0.8100 - val_loss: 0.6604\n",
      "Epoch 8/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 181ms/step - accuracy: 0.8278 - loss: 0.5946 - val_accuracy: 0.8119 - val_loss: 0.6475\n",
      "Epoch 9/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 181ms/step - accuracy: 0.8297 - loss: 0.5842 - val_accuracy: 0.8171 - val_loss: 0.6330\n",
      "Epoch 10/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 200ms/step - accuracy: 0.8339 - loss: 0.5657 - val_accuracy: 0.8218 - val_loss: 0.6166\n",
      "Epoch 11/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.8396 - loss: 0.5484 - val_accuracy: 0.8233 - val_loss: 0.6065\n",
      "Epoch 12/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 182ms/step - accuracy: 0.8400 - loss: 0.5443 - val_accuracy: 0.8243 - val_loss: 0.5959\n",
      "Epoch 13/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 179ms/step - accuracy: 0.8432 - loss: 0.5315 - val_accuracy: 0.8286 - val_loss: 0.5826\n",
      "Epoch 14/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.8486 - loss: 0.5155 - val_accuracy: 0.8307 - val_loss: 0.5792\n",
      "Epoch 15/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 180ms/step - accuracy: 0.8513 - loss: 0.5056 - val_accuracy: 0.8349 - val_loss: 0.5661\n",
      "Epoch 16/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 180ms/step - accuracy: 0.8533 - loss: 0.4992 - val_accuracy: 0.8363 - val_loss: 0.5613\n",
      "Epoch 17/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.8553 - loss: 0.4933 - val_accuracy: 0.8369 - val_loss: 0.5591\n",
      "Epoch 18/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.8566 - loss: 0.4875 - val_accuracy: 0.8386 - val_loss: 0.5556\n",
      "Epoch 19/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.8608 - loss: 0.4764 - val_accuracy: 0.8416 - val_loss: 0.5454\n",
      "Epoch 20/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.8614 - loss: 0.4728 - val_accuracy: 0.8452 - val_loss: 0.5384\n",
      "Epoch 21/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.8640 - loss: 0.4655 - val_accuracy: 0.8447 - val_loss: 0.5344\n",
      "Epoch 22/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.8673 - loss: 0.4549 - val_accuracy: 0.8457 - val_loss: 0.5326\n",
      "Epoch 23/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.8686 - loss: 0.4472 - val_accuracy: 0.8456 - val_loss: 0.5312\n",
      "Epoch 24/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.8704 - loss: 0.4431 - val_accuracy: 0.8484 - val_loss: 0.5254\n",
      "Epoch 25/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 188ms/step - accuracy: 0.8742 - loss: 0.4321 - val_accuracy: 0.8496 - val_loss: 0.5201\n",
      "Epoch 26/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.8735 - loss: 0.4324 - val_accuracy: 0.8497 - val_loss: 0.5176\n",
      "Epoch 27/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.8763 - loss: 0.4228 - val_accuracy: 0.8515 - val_loss: 0.5108\n",
      "Epoch 28/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.8792 - loss: 0.4135 - val_accuracy: 0.8529 - val_loss: 0.5077\n",
      "Epoch 29/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 188ms/step - accuracy: 0.8804 - loss: 0.4104 - val_accuracy: 0.8535 - val_loss: 0.5103\n",
      "Epoch 30/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 183ms/step - accuracy: 0.8821 - loss: 0.4028 - val_accuracy: 0.8554 - val_loss: 0.5003\n",
      "Epoch 31/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.8840 - loss: 0.3966 - val_accuracy: 0.8570 - val_loss: 0.4978\n",
      "Epoch 32/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.8861 - loss: 0.3917 - val_accuracy: 0.8560 - val_loss: 0.5007\n",
      "Epoch 33/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.8873 - loss: 0.3861 - val_accuracy: 0.8570 - val_loss: 0.4973\n",
      "Epoch 34/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.8886 - loss: 0.3815 - val_accuracy: 0.8591 - val_loss: 0.4933\n",
      "Epoch 35/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.8907 - loss: 0.3746 - val_accuracy: 0.8596 - val_loss: 0.4917\n",
      "Epoch 36/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.8914 - loss: 0.3722 - val_accuracy: 0.8603 - val_loss: 0.4889\n",
      "Epoch 37/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 182ms/step - accuracy: 0.8940 - loss: 0.3642 - val_accuracy: 0.8615 - val_loss: 0.4864\n",
      "Epoch 38/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 182ms/step - accuracy: 0.8945 - loss: 0.3611 - val_accuracy: 0.8615 - val_loss: 0.4861\n",
      "Epoch 39/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 189ms/step - accuracy: 0.8969 - loss: 0.3539 - val_accuracy: 0.8622 - val_loss: 0.4829\n",
      "Epoch 40/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.8977 - loss: 0.3501 - val_accuracy: 0.8615 - val_loss: 0.4875\n",
      "Epoch 41/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.8986 - loss: 0.3473 - val_accuracy: 0.8623 - val_loss: 0.4864\n",
      "Epoch 42/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.9003 - loss: 0.3412 - val_accuracy: 0.8631 - val_loss: 0.4834\n",
      "Epoch 43/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9014 - loss: 0.3371 - val_accuracy: 0.8630 - val_loss: 0.4850\n",
      "Epoch 44/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.9036 - loss: 0.3292 - val_accuracy: 0.8635 - val_loss: 0.4823\n",
      "Epoch 45/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9045 - loss: 0.3256 - val_accuracy: 0.8640 - val_loss: 0.4790\n",
      "Epoch 46/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.9059 - loss: 0.3214 - val_accuracy: 0.8646 - val_loss: 0.4805\n",
      "Epoch 47/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.9065 - loss: 0.3188 - val_accuracy: 0.8650 - val_loss: 0.4787\n",
      "Epoch 48/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9086 - loss: 0.3127 - val_accuracy: 0.8654 - val_loss: 0.4801\n",
      "Epoch 49/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9085 - loss: 0.3109 - val_accuracy: 0.8653 - val_loss: 0.4811\n",
      "Epoch 50/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 182ms/step - accuracy: 0.9104 - loss: 0.3056 - val_accuracy: 0.8665 - val_loss: 0.4783\n",
      "Epoch 51/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9125 - loss: 0.2991 - val_accuracy: 0.8670 - val_loss: 0.4782\n",
      "Epoch 52/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 181ms/step - accuracy: 0.9115 - loss: 0.3002 - val_accuracy: 0.8679 - val_loss: 0.4773\n",
      "Epoch 53/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9131 - loss: 0.2968 - val_accuracy: 0.8674 - val_loss: 0.4791\n",
      "Epoch 54/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.9154 - loss: 0.2884 - val_accuracy: 0.8670 - val_loss: 0.4821\n",
      "Epoch 55/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 181ms/step - accuracy: 0.9164 - loss: 0.2849 - val_accuracy: 0.8675 - val_loss: 0.4791\n",
      "Epoch 56/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.9172 - loss: 0.2827 - val_accuracy: 0.8667 - val_loss: 0.4835\n",
      "Epoch 57/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 182ms/step - accuracy: 0.9194 - loss: 0.2751 - val_accuracy: 0.8673 - val_loss: 0.4825\n",
      "Epoch 58/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.9207 - loss: 0.2705 - val_accuracy: 0.8664 - val_loss: 0.4836\n",
      "Epoch 59/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9202 - loss: 0.2721 - val_accuracy: 0.8683 - val_loss: 0.4819\n",
      "Epoch 60/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 180ms/step - accuracy: 0.9218 - loss: 0.2653 - val_accuracy: 0.8685 - val_loss: 0.4836\n",
      "Epoch 61/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 182ms/step - accuracy: 0.9225 - loss: 0.2641 - val_accuracy: 0.8677 - val_loss: 0.4867\n",
      "Epoch 62/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9235 - loss: 0.2600 - val_accuracy: 0.8683 - val_loss: 0.4868\n",
      "Epoch 63/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 181ms/step - accuracy: 0.9243 - loss: 0.2577 - val_accuracy: 0.8681 - val_loss: 0.4900\n",
      "Epoch 64/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9254 - loss: 0.2524 - val_accuracy: 0.8692 - val_loss: 0.4890\n",
      "Epoch 65/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 189ms/step - accuracy: 0.9265 - loss: 0.2502 - val_accuracy: 0.8684 - val_loss: 0.4932\n",
      "Epoch 66/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9277 - loss: 0.2456 - val_accuracy: 0.8693 - val_loss: 0.4901\n",
      "Epoch 67/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9289 - loss: 0.2408 - val_accuracy: 0.8685 - val_loss: 0.4921\n",
      "Epoch 68/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9296 - loss: 0.2385 - val_accuracy: 0.8689 - val_loss: 0.4934\n",
      "Epoch 69/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9303 - loss: 0.2360 - val_accuracy: 0.8687 - val_loss: 0.4981\n",
      "Epoch 70/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.9313 - loss: 0.2331 - val_accuracy: 0.8678 - val_loss: 0.5033\n",
      "Epoch 71/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 188ms/step - accuracy: 0.9319 - loss: 0.2307 - val_accuracy: 0.8683 - val_loss: 0.5029\n",
      "Epoch 72/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 188ms/step - accuracy: 0.9324 - loss: 0.2284 - val_accuracy: 0.8686 - val_loss: 0.5016\n",
      "Epoch 73/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 190ms/step - accuracy: 0.9342 - loss: 0.2234 - val_accuracy: 0.8684 - val_loss: 0.5040\n",
      "Epoch 74/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.9350 - loss: 0.2189 - val_accuracy: 0.8696 - val_loss: 0.5093\n",
      "Epoch 75/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 188ms/step - accuracy: 0.9355 - loss: 0.2176 - val_accuracy: 0.8696 - val_loss: 0.5062\n",
      "Epoch 76/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9369 - loss: 0.2137 - val_accuracy: 0.8700 - val_loss: 0.5062\n",
      "Epoch 77/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 186ms/step - accuracy: 0.9376 - loss: 0.2110 - val_accuracy: 0.8691 - val_loss: 0.5090\n",
      "Epoch 78/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 187ms/step - accuracy: 0.9384 - loss: 0.2082 - val_accuracy: 0.8693 - val_loss: 0.5100\n",
      "Epoch 79/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 188ms/step - accuracy: 0.9385 - loss: 0.2076 - val_accuracy: 0.8693 - val_loss: 0.5161\n",
      "Epoch 80/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9400 - loss: 0.2020 - val_accuracy: 0.8692 - val_loss: 0.5136\n",
      "Epoch 81/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.9406 - loss: 0.2017 - val_accuracy: 0.8695 - val_loss: 0.5177\n",
      "Epoch 82/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9412 - loss: 0.1984 - val_accuracy: 0.8693 - val_loss: 0.5212\n",
      "Epoch 83/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 188ms/step - accuracy: 0.9423 - loss: 0.1956 - val_accuracy: 0.8693 - val_loss: 0.5245\n",
      "Epoch 84/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 187ms/step - accuracy: 0.9434 - loss: 0.1917 - val_accuracy: 0.8698 - val_loss: 0.5238\n",
      "Epoch 85/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 183ms/step - accuracy: 0.9439 - loss: 0.1890 - val_accuracy: 0.8703 - val_loss: 0.5232\n",
      "Epoch 86/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 184ms/step - accuracy: 0.9446 - loss: 0.1875 - val_accuracy: 0.8689 - val_loss: 0.5269\n",
      "Epoch 87/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9453 - loss: 0.1836 - val_accuracy: 0.8694 - val_loss: 0.5324\n",
      "Epoch 88/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 185ms/step - accuracy: 0.9458 - loss: 0.1832 - val_accuracy: 0.8686 - val_loss: 0.5365\n",
      "Epoch 89/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 201ms/step - accuracy: 0.9463 - loss: 0.1810 - val_accuracy: 0.8693 - val_loss: 0.5379\n",
      "Epoch 90/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 314ms/step - accuracy: 0.9477 - loss: 0.1767 - val_accuracy: 0.8686 - val_loss: 0.5405\n",
      "Epoch 91/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 316ms/step - accuracy: 0.9481 - loss: 0.1742 - val_accuracy: 0.8688 - val_loss: 0.5421\n",
      "Epoch 92/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 315ms/step - accuracy: 0.9484 - loss: 0.1747 - val_accuracy: 0.8689 - val_loss: 0.5446\n",
      "Epoch 93/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 315ms/step - accuracy: 0.9489 - loss: 0.1719 - val_accuracy: 0.8689 - val_loss: 0.5460\n",
      "Epoch 94/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 312ms/step - accuracy: 0.9500 - loss: 0.1683 - val_accuracy: 0.8690 - val_loss: 0.5513\n",
      "Epoch 95/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 318ms/step - accuracy: 0.9504 - loss: 0.1656 - val_accuracy: 0.8697 - val_loss: 0.5506\n",
      "Epoch 96/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 316ms/step - accuracy: 0.9504 - loss: 0.1660 - val_accuracy: 0.8701 - val_loss: 0.5535\n",
      "Epoch 97/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 317ms/step - accuracy: 0.9517 - loss: 0.1618 - val_accuracy: 0.8689 - val_loss: 0.5600\n",
      "Epoch 98/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 321ms/step - accuracy: 0.9520 - loss: 0.1587 - val_accuracy: 0.8677 - val_loss: 0.5600\n",
      "Epoch 99/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 315ms/step - accuracy: 0.9528 - loss: 0.1577 - val_accuracy: 0.8689 - val_loss: 0.5641\n",
      "Epoch 100/100\n",
      "\u001B[1m125/125\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 315ms/step - accuracy: 0.9534 - loss: 0.1570 - val_accuracy: 0.8694 - val_loss: 0.5647\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T15:19:54.438472Z",
     "start_time": "2025-01-04T15:19:54.354513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder_inputs = model.input[0]  \n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  \n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ],
   "id": "cea63976412baf3b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T15:27:33.443572Z",
     "start_time": "2025-01-04T15:27:09.619041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "random_indices = random.sample(range(len(input_texts)), 10)\n",
    "\n",
    "for idx in random_indices:\n",
    "    input_seq = encoder_input_data[idx : idx + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(input_texts[idx], '---', decoded_sentence)\n"
   ],
   "id": "303078ffe31b38d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They're ugly. --- Вони старі.\n",
      "\n",
      "You must come. --- Ти можеш прихити.\n",
      "\n",
      "Who paid? --- Хто заплатив?\n",
      "\n",
      "I like soup. --- Мені подобається рик.\n",
      "\n",
      "They're dead. --- Вони старі.\n",
      "\n",
      "Wash the car. --- Помийте машину.\n",
      "\n",
      "Tom is skinny. --- Том старий.\n",
      "\n",
      "I helped him. --- Я йому допоміг.\n",
      "\n",
      "What's inside? --- Що це таке?\n",
      "\n",
      "Tom is strict. --- Том старий.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
